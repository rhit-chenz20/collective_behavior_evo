---
title: "plot genotype, phenotype and effect size data"
author: "Andrea Chen"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
setwd("/workdir/zc524/collective_behavior_evo/r_remote")
base_data_folder <- "../data/n_group_base_data"
base_plot_folder <- "../r_plots/n_group_base"
target_psi <- c(-0.9, -0.6, -0.3, 0.0, 0.3, 0.6, 0.9)
```

# load GENOTYPE data
```{r}
# Set the top-level folder
folder <- paste0(base_data_folder, "/genotype")

# List all .tsv files recursively
file_list <- list.files(
  path = folder,
  pattern = "\\.tsv$",
  full.names = TRUE,
  recursive = TRUE
)

# Function to extract metadata from path
extract_geno_metadata <- function(path) {
  matches <- regexec("genotype/n_(\\d+)_psi_(-?[0-9.]+)_(\\d+)\\.tsv", path)
  parts <- regmatches(path, matches)[[1]]

  if (length(parts) != 4) {
    warning("Could not extract metadata from path: ", path, " with matches: ", paste(parts, collapse = ", "))
    return(data.frame())
  }

  data.frame(
    n = as.integer(parts[2]),
    psi = as.numeric(parts[3]),
    rep = as.integer(parts[4]),
    stringsAsFactors = FALSE
  )
}

# Read and combine all files
genotype_df <- do.call(rbind, lapply(file_list, function(file) {
  df <- read.table(file, header = TRUE, sep = "\t")
  meta <- extract_geno_metadata(file)
  if (nrow(meta) == 0) return(NULL)

  # Compute new job_id
  df$rep <- meta$rep
  df$psi <- meta$psi
  df$n <- meta$n
  df$file_id <- basename(file)

  return(df)
}))

```

# plot GENOTYPE histogram
```{r}
library(RColorBrewer)
# Assuming you want to focus on a specific generation (e.g., 10100)
df <- subset(genotype_df, generation == 9999)
target_gen <- 9999

# Define histogram bins
num_bins <- 100
bin_breaks <- seq(-50, 50, length.out = num_bins + 1)
bin_mids <- 0.5 * (head(bin_breaks, -1) + tail(bin_breaks, -1))

# Color setup
psi_vals <- target_psi
colors <- rainbow(length(psi_vals))
names(colors) <- as.character(psi_vals)
```

## plot GENOTYPE histogram for each run
```{r}
for (n_val in sort(unique(df$n))) {
  df_n <- subset(genotype_df, generation == target_gen & n == n_val)
  psi_vals <- sort(unique(df_n$psi))
  colors <- hcl.colors(length(psi_vals), palette = "Zissou 1")
  names(colors) <- as.character(psi_vals)

  # Estimate ymax across all (psi, rep) combos
  unique_combos <- unique(df_n[, c("psi", "rep")])
  max_y <- 0
  for (i in seq_len(nrow(unique_combos))) {
    psi_val <- unique_combos$psi[i]
    rep_val <- unique_combos$rep[i]
    row <- subset(df_n, psi == psi_val & rep == rep_val)[1, ]
    values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
    h <- hist(values, breaks=bin_breaks, plot=FALSE)
    max_y <- max(max_y, max(h$counts / sum(h$counts)))
  }

  # Plot
  png(file.path(base_plot_folder, paste0("genotype_hist_reps_n_", n_val, ".png")), width=1000, height=700)
  plot(NULL, xlim=range(bin_breaks), ylim=c(0, max_y), xlab="Genotype Value", ylab="Proportion",
       main=paste("Genotype Histogram by Rep | n =", n_val))

  for (i in seq_len(nrow(unique_combos))) {
    psi_val <- unique_combos$psi[i]
    rep_val <- unique_combos$rep[i]
    row <- subset(df_n, psi == psi_val & rep == rep_val)[1, ]
    values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
    h <- hist(values, breaks=bin_breaks, plot=FALSE)
    lines(bin_mids, h$counts / sum(h$counts), col=colors[as.character(psi_val)])
  }

  # Add Gaussian fitness curve
  Vs <- sqrt(2000)
  z_vals <- seq(min(bin_breaks), max(bin_breaks), length.out = 500)
  W_z <- exp(- (z_vals^2) / (2 * Vs))

  # Rescale W_z to match plot height
  W_z_scaled <- W_z / max(W_z) * max_y  # max_y = ylim[2] used in your plot

  # Add the line
  lines(z_vals, W_z_scaled, col = "black", lwd = 2, lty = 2)

  legend("topright", legend=paste0("psi=", psi_vals), col=colors, lty=1, cex=0.8)
  dev.off()
}

```

## plot average GENOTYPE for each psi
```{r}
for (n_val in sort(unique(df$n))) {
  df_n <- subset(genotype_df, generation == target_gen & n == n_val)
  psi_vals <- sort(unique(df_n$psi))
  colors <- hcl.colors(length(psi_vals), palette = "Zissou 1")
  names(colors) <- as.character(psi_vals)

  # Estimate max_y across all averaged psi histograms
  max_y <- 0
  for (psi_val in psi_vals) {
    df_psi <- subset(df_n, psi == psi_val)
    rep_combos <- unique(df_psi[, c("rep", "psi")])
    num_reps <- nrow(rep_combos)

    counts_mat <- matrix(NA, nrow=num_reps, ncol=num_bins)
    for (i in seq_len(num_reps)) {
      rep_val <- rep_combos$rep[i]
      row <- subset(df_psi, rep == rep_val)[1, ]
      values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
      h <- hist(values, breaks=bin_breaks, plot=FALSE)
      counts_mat[i, ] <- h$counts / sum(h$counts)
    }
    avg_counts <- colMeans(counts_mat, na.rm=TRUE)
    max_y <- max(max_y, max(avg_counts, na.rm=TRUE))
  }

  # Plot
  png(file.path(base_plot_folder, paste0("genotype_hist_avg_n_", n_val, ".png")), width=1000, height=700)
  plot(NULL, xlim=range(bin_breaks), ylim=c(0, max_y), xlab="Genotype Value", ylab="Proportion",
       main=paste("Avg Genotype Histogram | n =", n_val))

  for (psi_val in psi_vals) {
    df_psi <- subset(df_n, psi == psi_val)
    rep_combos <- unique(df_psi[, c("rep", "psi")])
    num_reps <- nrow(rep_combos)

    counts_mat <- matrix(NA, nrow=num_reps, ncol=num_bins)
    for (i in seq_len(num_reps)) {
      rep_val <- rep_combos$rep[i]
      row <- subset(df_psi, rep == rep_val)[1, ]
      values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
      h <- hist(values, breaks=bin_breaks, plot=FALSE)
      counts_mat[i, ] <- h$counts / sum(h$counts)
    }

    avg_counts <- colMeans(counts_mat, na.rm=TRUE)
    lines(bin_mids, avg_counts, col=colors[as.character(psi_val)], lwd=2)
  }

  # Add Gaussian fitness curve
  Vs <- sqrt(2000)
  z_vals <- seq(min(bin_breaks), max(bin_breaks), length.out = 500)
  W_z <- exp(- (z_vals^2) / (2 * Vs))

  # Rescale W_z to match plot height
  W_z_scaled <- W_z / max(W_z) * max_y  # max_y = ylim[2] used in your plot

  # Add the line
  lines(z_vals, W_z_scaled, col = "black", lwd = 2, lty = 2)

  legend("topright", legend=paste0("psi=", psi_vals), col=colors, lty=1, lwd=2, cex=0.8)
  dev.off()
}

```


# load PHENOTYPE data
```{r}
# Set the top-level folder
folder <- paste0(base_data_folder, "/phenotype")

# List all .tsv files recursively
file_list <- list.files(
  path = folder,
  pattern = "\\.tsv$",
  full.names = TRUE,
  recursive = TRUE
)

# Function to extract metadata from path
extract_pheno_metadata <- function(path) {
  matches <- regexec("phenotype/n_(\\d+)_psi_(-?[0-9.]+)_(\\d+)\\.tsv", path)
  parts <- regmatches(path, matches)[[1]]

  if (length(parts) != 4) {
    warning("Could not extract metadata from path: ", path, " with matches: ", paste(parts, collapse = ", "))
    return(data.frame())
  }

  data.frame(
    n = as.integer(parts[2]),
    psi = as.numeric(parts[3]),
    rep = as.integer(parts[4]),
    stringsAsFactors = FALSE
  )
}

# Read and combine all files
phenotype_df <- do.call(rbind, lapply(file_list, function(file) {
  df <- read.table(file, header = TRUE, sep = "\t")
  meta <- extract_pheno_metadata(file)
  if (nrow(meta) == 0) return(NULL)

  # Compute new job_id
  df$rep <- meta$rep
  df$psi <- meta$psi
  df$n <- meta$n
  df$file_id <- basename(file)

  return(df)
}))
```

# plot PHENOTYPE histogram 
```{r}
# Assuming you want to focus on a specific generation (e.g., 10100)
df <- subset(phenotype_df, generation == 9999)
target_gen <- 9999

# Define histogram bins
num_bins <- 280
bin_breaks <- seq(-120, 120, length.out = num_bins + 1)
bin_mids <- 0.5 * (head(bin_breaks, -1) + tail(bin_breaks, -1))

# Color setup
psi_vals <- target_psi
colors <- rainbow(length(psi_vals))
names(colors) <- as.character(psi_vals)
```

## plot PHENOTYPE histogram for each run
```{r}
for (n_val in sort(unique(df$n))) {
  df_n <- subset(phenotype_df, generation == target_gen & n == n_val)
  psi_vals <- sort(unique(df_n$psi))
  colors <- hcl.colors(length(psi_vals), palette = "Zissou 1")
  names(colors) <- as.character(psi_vals)

  # Estimate ymax across all (psi, rep) combos
  unique_combos <- unique(df_n[, c("psi", "rep")])
  max_y <- 0
  for (i in seq_len(nrow(unique_combos))) {
    psi_val <- unique_combos$psi[i]
    rep_val <- unique_combos$rep[i]
    row <- subset(df_n, psi == psi_val & rep == rep_val)[1, ]
    values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
    h <- hist(values, breaks=bin_breaks, plot=FALSE)
    max_y <- max(max_y, max(h$counts / sum(h$counts)))
  }

  # Plot
  png(file.path(base_plot_folder, paste0("phenotype_hist_reps_n_", n_val, ".png")), width=1000, height=700)
  plot(NULL, xlim=range(bin_breaks), ylim=c(0, max_y), xlab="Phenotype Value", ylab="Proportion",
       main=paste("Phenotype Histogram by Rep | n =", n_val))

  for (i in seq_len(nrow(unique_combos))) {
    psi_val <- unique_combos$psi[i]
    rep_val <- unique_combos$rep[i]
    row <- subset(df_n, psi == psi_val & rep == rep_val)[1, ]
    values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
    h <- hist(values, breaks=bin_breaks, plot=FALSE)
    lines(bin_mids, h$counts / sum(h$counts), col=colors[as.character(psi_val)])
  }

  # Add Gaussian fitness curve
  Vs <- sqrt(2000)
  z_vals <- seq(min(bin_breaks), max(bin_breaks), length.out = 500)
  W_z <- exp(- (z_vals^2) / (2 * Vs))

  # Rescale W_z to match plot height
  W_z_scaled <- W_z / max(W_z) * max_y  # max_y = ylim[2] used in your plot

  # Add the line
  lines(z_vals, W_z_scaled, col = "black", lwd = 2, lty = 2)

  legend("topright", legend=paste0("psi=", psi_vals), col=colors, lty=1, cex=0.8)
  dev.off()
}

```

## plot average PHENOTYPE histogram for each psi
```{r}
for (n_val in sort(unique(df$n))) {
  df_n <- subset(phenotype_df, generation == target_gen & n == n_val)
  psi_vals <- sort(unique(df_n$psi))
  colors <- hcl.colors(length(psi_vals), palette = "Zissou 1")
  names(colors) <- as.character(psi_vals)

  # Estimate max_y across all averaged psi histograms
  max_y <- 0
  for (psi_val in psi_vals) {
    df_psi <- subset(df_n, psi == psi_val)
    rep_combos <- unique(df_psi[, c("rep", "psi")])
    num_reps <- nrow(rep_combos)

    counts_mat <- matrix(NA, nrow=num_reps, ncol=num_bins)
    for (i in seq_len(num_reps)) {
      rep_val <- rep_combos$rep[i]
      row <- subset(df_psi, rep == rep_val)[1, ]
      values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
      h <- hist(values, breaks=bin_breaks, plot=FALSE)
      counts_mat[i, ] <- h$counts / sum(h$counts)
    }
    avg_counts <- colMeans(counts_mat, na.rm=TRUE)
    max_y <- max(max_y, max(avg_counts, na.rm=TRUE))
  }

  # Plot
  png(file.path(base_plot_folder, paste0("phenotype_hist_avg_n_", n_val, ".png")), width=1000, height=700)
  plot(NULL, xlim=range(bin_breaks), ylim=c(0, max_y), xlab="Phenotype Value", ylab="Proportion",
       main=paste("Avg Phenotype Histogram | n =", n_val))

  for (psi_val in psi_vals) {
    df_psi <- subset(df_n, psi == psi_val)
    rep_combos <- unique(df_psi[, c("rep", "psi")])
    num_reps <- nrow(rep_combos)

    counts_mat <- matrix(NA, nrow=num_reps, ncol=num_bins)
    for (i in seq_len(num_reps)) {
      rep_val <- rep_combos$rep[i]
      row <- subset(df_psi, rep == rep_val)[1, ]
      values <- as.numeric(as.vector(unlist(row[ , grep("^X", names(row))])))
      h <- hist(values, breaks=bin_breaks, plot=FALSE)
      counts_mat[i, ] <- h$counts / sum(h$counts)
    }

    avg_counts <- colMeans(counts_mat, na.rm=TRUE)
    lines(bin_mids, avg_counts, col=colors[as.character(psi_val)], lwd=2)
  }

  # Add Gaussian fitness curve
  Vs <- sqrt(2000)
  z_vals <- seq(min(bin_breaks), max(bin_breaks), length.out = 500)
  W_z <- exp(- (z_vals^2) / (2 * Vs))

  # Rescale W_z to match plot height
  W_z_scaled <- W_z / max(W_z) * max_y  # max_y = ylim[2] used in your plot

  # Add the line
  lines(z_vals, W_z_scaled, col = "black", lwd = 2, lty = 2)

  legend("topright", legend=paste0("psi=", psi_vals), col=colors, lty=1, lwd=2, cex=0.8)
  dev.off()
}

```

# load SUMMARY STATS data
```{r}
# Set the top-level folder
folder <- paste0(base_data_folder, "/data")

# List all .tsv files recursively
file_list <- list.files(
  path = folder,
  pattern = "\\.tsv$",
  full.names = TRUE,
  recursive = TRUE
)

# Function to extract metadata from path
extract_sum_metadata <- function(path) {
  matches <- regexec("data/n_(\\d+)_psi_(-?[0-9.]+)_(\\d+)\\.tsv", path)
  parts <- regmatches(path, matches)[[1]]

  if (length(parts) != 4) {
    warning("Could not extract metadata from path: ", path)
    return(data.frame())
  }

  data.frame(
    n = as.integer(parts[2]),
    stringsAsFactors = FALSE
  )
}

# Read and combine all files
summary_stat_df <- do.call(rbind, lapply(file_list, function(file) {
  df <- read.table(file, header = TRUE, sep = "\t")
  meta <- extract_sum_metadata(file)
  if (nrow(meta) == 0) return(NULL)

  # Compute new job_id
  df$n <- meta$n
  df$file_id <- basename(file)

  return(df)
}))

```

## plot SUMMARY STATS (z_sd over n)
```{r}
df <- subset(summary_stat_df, tick == 9999)
n_vals <- sort(unique(df$n))
psi_vals <- sort(unique(df$psi))

colors <- hcl.colors(length(psi_vals), palette = "Berlin")
names(colors) <- as.character(psi_vals)

```

### z_sd over n per rep
```{r}
png(file.path(base_plot_folder, "z_sd_vs_n_reps.png"), width = 1000, height = 700)
plot(NULL, xlim = range(n_vals), ylim = range(df$z_sd, na.rm = TRUE),
     xlab = "n", ylab = "z_sd", main = "z_sd vs n @ tick 9999 (Per Rep)")

for (psi_val in psi_vals) {
  df_psi <- subset(df, psi == psi_val)
  for (n_val in n_vals) {
    points(rep(n_val, sum(df_psi$n == n_val)),
           df_psi$z_sd[df_psi$n == n_val],
           col = colors[as.character(psi_val)], pch = 1)
  }
}
legend("topright", legend = paste0("psi=", psi_vals), col = colors, pch = 16, cex = 0.8)
dev.off()


```

### z_sd over n averaged
```{r}
png(file.path(base_plot_folder, "z_sd_vs_n_avg.png"), width = 1000, height = 700)
plot(NULL, xlim = range(n_vals), ylim = range(df$z_sd, na.rm = TRUE),
     xlab = "n", ylab = "z_sd", main = "z_sd vs n @ tick 9999 (Averaged)")

for (psi_val in psi_vals) {
  df_psi <- subset(df, psi == psi_val)
  for (n_val in n_vals) {
    subset_rows <- df_psi[df_psi$n == n_val, ]
    if (nrow(subset_rows) > 0) {
      avg <- mean(subset_rows$z_sd, na.rm = TRUE)
      points(n_val, avg, col = colors[as.character(psi_val)], pch = 16, cex = 1.5)
    }
  }
}
legend("topright", legend = paste0("psi=", psi_vals), col = colors, pch = 16, cex = 0.8)
dev.off()


```

### a_sd over n per rep
```{r}
png(file.path(base_plot_folder, "a_sd_vs_n_reps.png"), width = 1000, height = 700)
plot(NULL, xlim = range(n_vals), ylim = range(df$a_sd, na.rm = TRUE),
     xlab = "n", ylab = "a_sd", main = "a_sd vs n @ tick 9999 (Per Rep)")

for (psi_val in psi_vals) {
  df_psi <- subset(df, psi == psi_val)
  for (n_val in n_vals) {
    points(rep(n_val, sum(df_psi$n == n_val)),
           df_psi$a_sd[df_psi$n == n_val],
           col = colors[as.character(psi_val)], pch = 1)
  }
}
legend("topright", legend = paste0("psi=", psi_vals), col = colors, pch = 16, cex = 0.8)
dev.off()

```

### a_sd over n averaged
```{r}
png(file.path(base_plot_folder, "a_sd_vs_n_avg.png"), width = 1000, height = 700)
plot(NULL, xlim = range(n_vals), ylim = range(df$a_sd, na.rm = TRUE),
     xlab = "n", ylab = "a_sd", main = "a_sd vs n @ tick 9999 (Averaged)")

for (psi_val in psi_vals) {
  df_psi <- subset(df, psi == psi_val)
  for (n_val in n_vals) {
    subset_rows <- df_psi[df_psi$n == n_val, ]
    if (nrow(subset_rows) > 0) {
      avg <- mean(subset_rows$a_sd, na.rm = TRUE)
      points(n_val, avg, col = colors[as.character(psi_val)], pch = 16, cex = 1.5)
    }
  }
}
legend("topright", legend = paste0("psi=", psi_vals), col = colors, pch = 16, cex = 0.8)
dev.off()
```



## process ind data
```{r}
# ---- CONFIG ----
library(tools)

folder <- paste0(base_data_folder, "/ind")
gen_filter <- "9999"     # generation to keep

# ---- HELPERS ----

# Extract metadata from filename
extract_effect_metadata <- function(path) {
  # matches <- regexec(paste0("ind_(\\d+)_([1-3])/n_(\\d+)/rec_N_1000_psi_(-?[0-9.]+)_pop_(\\d+)_1_gen10099\\.tsv"), path)
  matches <- regexec(paste0("ind/n_(\\d+)_psi_(-?[0-9.]+)_(\\d+)_gen",gen_filter,"\\.tsv"), path)
  parts <- regmatches(path, matches)[[1]]
  if (length(parts) != 4) {
    warning("Could not extract metadata from path: ", path, " with matches: ", paste(parts, collapse = ", "))
    return(data.frame())
  }
  list(
    n = as.integer(parts[2]),
    psi = as.numeric(parts[3]),
    rep = as.integer(parts[4]),
    file_id = basename(path)
  )
}

# Read variable-length TSV file, pad with NA
read_variable_tsv <- function(file_path) {
  lines <- readLines(file_path)
  if (length(lines) == 0) return(NULL)
  split_lines <- strsplit(lines, "\t")
  max_len <- max(sapply(split_lines, length))
  padded <- lapply(split_lines, function(row) {
    length(row) <- max_len
    row
  })
  df <- as.data.frame(do.call(rbind, padded), stringsAsFactors = FALSE)
  names(df)[1:2] <- c("generation", "individual_id")
  return(df)
}
```

```{r}
# ---- READ FILES ----

# Format for matching in filename (convert to character)
target_strs <- sprintf("psi_%s", formatC(target_psi, format = "f", digits = 1))

# List all matching generation files
file_list <- list.files(
  path = folder,
  pattern = paste0("_gen", gen_filter,"\\.tsv$"),
  full.names = TRUE,
  recursive = TRUE
)

# Filter: only keep files with a matching psi string
file_list <- Filter(function(f) {
  any(sapply(target_strs, function(p) grepl(p, f, fixed = TRUE)))
}, file_list)

# Read and collect all data frames into a list
df_list <- list()
for (file in file_list) {
  df <- read_variable_tsv(file)
  if (is.null(df)) next
  meta <- extract_effect_metadata(file)
  if (is.null(meta)) next
  n_cols <- ncol(df)

  # Store as list with metadata appended
  df$rep <- meta$rep
  df$psi <- meta$psi
  df$n <- meta$n
  df$file_id <- meta$file_id

  df_list[[length(df_list) + 1]] <- df
}
```


```{r}
# ---- PROCESS ----

# Determine max number of mutation columns (exclude 2 main + 4 meta)
max_mut_cols <- max(sapply(df_list, function(x) ncol(x) - 6))

# Reformat and reorder each df
reordered_list <- lapply(df_list, function(df) {
  n <- ncol(df)
  head_cols <- df[, 1:2]  # generation, individual_id
  meta_cols <- df[, (n - 3):n]
  mut_cols <- df[, 3:(n - 4)]

  # Pad mutation columns
  n_mut <- ncol(mut_cols)
  if(is.null(n_mut) || n_mut == 0) {
    return(NULL)  # Skip empty mutation columns
  }

  if (n_mut < max_mut_cols) {
    mut_cols <- cbind(mut_cols, matrix(NA, nrow = nrow(mut_cols), ncol = max_mut_cols - n_mut))
  }

  colnames(head_cols) <- c("generation", "individual_id")
  colnames(meta_cols) <- c("rep", "psi", "n",  "file_id")
  colnames(mut_cols) <- paste0("mut_", seq_len(ncol(mut_cols)))

  cbind(head_cols, meta_cols, mut_cols)
})

# Combine into final dataframe
effect_df <- do.call(rbind, reordered_list)

# ---- OPTIONAL SAVE ----
saveRDS(effect_df, file = paste0(base_data_folder, paste0("/ind/effect_df_gen", gen_filter,"_cleaned.rds")))

```

# load IND data
```{r}
# Load the cleaned effect data
effect_df <- readRDS(file = paste0(base_data_folder, "/ind/effect_df_gen", gen_filter, "_cleaned.rds"))
```

## plot EFFECT SIZE histogram 
```{r}
# Get mutation columns
mut_cols <- grep("^mut_", names(effect_df), value = TRUE)

# Define histogram bins
num_bins <- 100
bin_breaks <- seq(-5, 5, length.out = num_bins + 1)
bin_mids <- 0.5 * (head(bin_breaks, -1) + tail(bin_breaks, -1))

# Get color palette
psi_vals <- sort(unique(effect_df$psi))
colors <- hcl.colors(length(psi_vals), palette = "Berlin")
names(colors) <- as.character(psi_vals)

# Get all n values
n_vals <- sort(unique(effect_df$n))

```

```{r}
for (n_val in n_vals) {
  df_n <- subset(effect_df, n == n_val)
  unique_combos <- unique(df_n[, c("psi", "rep")])
  
  png(file.path(base_plot_folder, paste0("effect_size_indlevel_reps_n_", n_val, ".png")),
      width=1000, height=700)
  plot(NULL, xlim=range(bin_breaks), ylim=c(0, 0.15),
       xlab="Effect Size", ylab="Proportion",
       main=paste("Effect Size Dist. (Per Rep) | n =", n_val))
  
  for (i in seq_len(nrow(unique_combos))) {
    psi_val <- unique_combos$psi[i]
    rep_val <- unique_combos$rep[i]
    
    sub_df <- subset(df_n, psi == psi_val & rep == rep_val)
    indiv_mat <- matrix(0, nrow = nrow(sub_df), ncol = num_bins)
    
    for (j in seq_len(nrow(sub_df))) {
      entries <- na.omit(as.character(unlist(sub_df[j, mut_cols])))
      effect_sizes <- as.numeric(sub(":.*", "", sub(".*:", "", entries)))
      if (length(effect_sizes) > 0) {
        h <- hist(effect_sizes, breaks = bin_breaks, plot = FALSE)
        indiv_mat[j, ] <- h$counts / sum(h$counts)
      }
    }
    
    indiv_avg <- colMeans(indiv_mat, na.rm = TRUE)
    lines(bin_mids, indiv_avg, col=colors[as.character(psi_val)], lwd=1)
  }

  legend("topright", legend = paste0("psi=", psi_vals), col = colors, lty = 1, lwd = 2, cex = 0.8)
  dev.off()
}

```


# load MUT data TODO
```{r}
# Set the top-level folder
folder <- file.path(base_data_folder, "mut")

# List all .tsv files recursively
file_list <- list.files(
  path = folder,
  pattern = "\\.tsv$",
  full.names = TRUE,
  recursive = TRUE
)

# Function to extract metadata from path
extract_mut_metadata <- function(path) {
  matches <- regexec("mut/n_(\\d+)_psi_(-?[0-9.]+)_(\\d+)\\.tsv", path)
  parts <- regmatches(path, matches)[[1]]
  
  if (length(parts) != 4) {
    warning("Could not extract metadata from path: ", path)
    return(data.frame())
  }

  data.frame(
    n = as.integer(parts[2]),
    psi = as.numeric(parts[3]),
    rep = as.integer(parts[4]),
    stringsAsFactors = FALSE
  )
}

# Read and combine all files
mut_df <- do.call(rbind, lapply(file_list, function(file) {
  meta <- extract_mut_metadata(file)
  if (nrow(meta) == 0) return(NULL)

  raw_lines <- readLines(file)
  if (length(raw_lines) < 2) return(NULL)  # skip empty/broken files

  header <- strsplit(raw_lines[1], "\t")[[1]]
  num_cols <- length(header)

  # Parse even-numbered rows only (effect sizes)
  out_list <- list()
  for (i in seq(2, length(raw_lines), by = 2)) {
    row_vals <- strsplit(raw_lines[i], "\t")[[1]]
    num_vals <- length(row_vals)
    if (num_vals < 2) next  # skip short rows

    # Last column = generation number
    gen <- as.integer(row_vals[num_vals])
    
    # Remaining values = effect sizes
    effect_vals <- row_vals[1:(num_vals - 1)]
    
    # Pad to match header length if necessary
    if (length(effect_vals) < num_cols - 1) {
      effect_vals <- c(effect_vals, rep(NA, (num_cols - 1) - length(effect_vals)))
    }

    # Construct data frame: one row per effect
    df <- data.frame(
      generation = gen,
      mut_col = header[1:(num_cols - 1)],
      effect_size = as.numeric(effect_vals),
      n = meta$n,
      psi = meta$psi,
      rep = meta$rep,
      file_id = basename(file),
      stringsAsFactors = FALSE
    )

    out_list[[length(out_list) + 1]] <- df
  }

  do.call(rbind, out_list)
}))

```



